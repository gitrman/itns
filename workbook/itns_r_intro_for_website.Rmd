---
title: "Getting Started with the New Statistics in R"
author: "David Erceg-Hurn, Geoff Cumming, Robert Calin-Jageman"
date: "`r Sys.Date()`"
output: 
  pdf_document:
    latex_engine: xelatex
    fig_width: 6
    fig_height: 4.5
mainfont: "Arial"
urlcolor: blue
---

# Overview
[R](https://www.r-project.org/) is a popular and powerful free program that can be used to conduct most of the statistical analyses outlined in *Introduction to the New Statistics*.  Unlike programs such as SPSS where analyses are usually conducted by clicking on menus, in R analyses are typically performed by typing *commands*.

This document is a brief guide that will help you to get started using the 'new statistics' in R.  The guide is split into three sections.  The first section provides some tips about installing and learning the basics of R.  If you've never used R before you should read this section - if you already know how to use R you can skip it. The second section provides a brief overview of a new R package, [itns](https://github.com/gitrman/itns), that contains the datasets used in *Introduction to the New Statistics*.  You can use the datasets in the *itns* package to work through the examples covered in the book and the end-of-chapter exercises.  The final section provides a short overview of R packages and functions that can be used to conduct the analyses covered in *Introdudction to the New Statistics*.

You will notice that some words in this document are a blue colour.  These are hyperlinks.  If you click on the blue text, you will be redirected to websites that contain information about using R.

# Part One - Installing R and Learning the Basics

To install R, visit the 
[RStudio website and following the installation instructions](https://www.rstudio.com/resources/training/online-learning/#R).  That webpage also contains links to interactive tutorials for R beginners.  The tutorials will help you learn how to perform basic tasks like importing and manipulating datasets.  Other useful resources for learning R include:

* [R for Data Science](http://r4ds.had.co.nz/) - An online book by Garrett Grolemund and Hadley Wickham that will teach you how to import, tidy, and explore data.
* [Kelly Black's R Tutorial](http://www.cyclismo.org/tutorial/R/index.html) - An introductory tutorial focusing on the basics of R.
* [How to Learn R Blog](http://www.r-bloggers.com/how-to-learn-r-2) - A collection of resources that will help you learn R.
* [Quick-R](http://www.statmethods.net) - A website that contains example code for running basic analyses.
* [R Quick Reference Card](http://cran.r-project.org/doc/contrib/Short-refcard.pdf) - A list of key commands built into R.

Also remember that Google is your friend.  If you have a question about how to do something in R, it is likely that someone else has already asked the same question and that there is an answer on the Internet. For example if you type 'R how to create a histogram' into Google, you will find many links to webpages showing you the R code that you need to plot a histogram.

In the remainder of the document, we assume that you have a basic understanding of how to use R.

# Part Two - The *itns* Dataset Package

'[itns](https://github.com/gitrman/itns)' is an R package which contains most of the datasets used in *Introduction to the New Statistics*.  The datasets were converted from Microsoft Excel files (found on the book's website) into R data frames.  The table on the next page lists the names of the data frames in the package, and the sections of the book where they are mentioned:

\pagebreak

**`itns` Package Data Frames**

Name            |Section                  |Topic 
---------------|------------------------|-----------------------------------
college_survey1     |Ch 3 End of Chapter Exercises 2 & 3  |Descriptive Statistics & Plots
religious_belief    |Ch 3 End of Chapter Exercise 4       |Descripitive Statistics & Plots
college_survey1     |Ch 5 End of Chapter Exercises 2 & 3  |Single Sample Confidence Interval
college_survey2     |Ch 5 End of Chapter Excercise 4      |Single Sample Confidence Interval
stickgold           |Ch 6 End of Chapter Exercise 5       |Single Sample Confidence Interval
pen_laptop1         |Ch 7.6-7.12                          |Two Independent Groups
pen_laptop2         |Ch 7.36-7.38                         |Two Independent Groups
anchor_estimate     |Ch 7 End of Chapter Exercise 3       |Two Independent Groups
clean_moral1        |Ch 7 End of Chapter Exercise 4       |Two Independent Groups
clean_moral2        |Ch 7 End of Chapter Exercise 4       |Two Independent Groups
math_gender_iat     |Ch 7 End of Chapter Exercise 5       |Two Independent Groups
thomason1           |Ch 8, 11, 12                         |Two Dependent Groups, Scatterplots, Regression
thomason2           |Ch 8                                 |Two Dependent Groups
thomason3           |Ch 8, 12.18                          |Two Dependent Groups, Regression
emotion_heartrate    |Ch 8 End of Chapter Exercise 3       |Two Dependent Groups
labels_flavor       |Ch 8 End of Chapter Exercise 4       |Two Dependent Groups
ma_anchor_adjust    |Ch9 End of Chapter Exercise 1        |Meta-Analysis
ma_flag_priming     |Ch9 End of Chapter Exercise 2        |Meta-Analysis
ma_math_gender_iat  |Ch9 End of Chapter Exercise 3        |Meta-Analysis
ma_power_performance|Ch9 End of Chapter Exercise 4        |Meta-Analysis
body_well           |Ch 11, 12                            |Correlation, Regression
exam_scores         |Ch 11 End of Chapter Exericse 2      |Correlation
sleep_beauty        |Ch 11 End of Chapter Exericse 6      |Correlation
campus_involvement  |Ch 11 End of Chapter Exericse 7      |Correlation
home_prices         |Ch 12 End of Chapter Exercise 2      |Regression
home_prices_holdout |Ch 12 End of Chapter Excerise 2h     |Regression
altruism_happiness  |Ch 12 End of Chapter Exercise 3      |Regression
rattan              |Ch 14.10-14.12                       |One-Way Independent Group Contrasts and Comparisons
organic_moral       |Ch 14 End of Chapter Exercise 5      |One-Way Independent Group Contrasts and Comparisons
videogame_aggression|Ch 15 End of Chapter Exercise 3      |Analysing factorial designs
self_explain_time   |Ch 15 End of Chapter Exercise 4      |Analysing factorial designs
natsal              |Ch 16.11                             |Robust Methods - Two Independent Groups
dana                |Ch 16 End of Chapter Exercise 3      |Robust Methods - Two Independent Groups

The `itns` package is not yet on [CRAN](https://cran.r-project.org), but can be downloaded from [github](https://github.com/gitrman/itns) using the `devtools` package:

```{r eval=FALSE}
 # install.packages("devtools")
 library(devtools)
 install_github("gitrman/itns")
```

Once you have installed the package, you can use the `library()` function to load it, `str()` to examine metadata for each data frame, and functions such as `head()` and `tail()` to print the first or last few rows to your screen.

```{r}
 library(itns)     # loads the package
 str(pen_laptop1)  # displays metadata
 head(pen_laptop1) # prints the first few rows
 tail(pen_laptop1) # prints the last few rows
```

To access further details about each dataset, type a question mark and the name of the dataset, for example:
```{r eval=FALSE}
  ?pen_laptop1
```

or access the PDF help file **LINK TO GO HERE** on the [itns github site](https://github.com/gitrman/itns).

The datasets in the `itns` package can be used to replicate analyses that appear in *Introduction to the New Statistics*, and to work through the book's end-of-chapter exercises using the packages and functions outlined in the next section of this guide.

# Part 3 - Helpful Packages and Functions
Most of the analyses described in *Introduction to the New Statistics* can be conducted using inbuilt R functions, or functions in packages that can be downloaded from CRAN or github.  In this section we mention some useful functions and packages, and resources that will help you learn how to use them.  This section is *not* intended to be a comprehensive tutorial on how to use each function; rather, our aim is to point you in the direction of resources already on the Internet that will help you learn how to use the packages and functions we mention.

## Basic Descriptive Statistics
Functions to compute basic descriptive statistics are built into R.  These include `mean()`, `median()`, `minimum()`, `maximum()`, `var` for variance, `sd()` for  the standard deviation, `IQR()` for interquantile range, `range()`, `quantile()` for percentiles, and `summary()` which for numeric variables returns the minimum, 25th percentile, median, mean, 75th percentile, and maximum.  Some examples of these functions in action are given below.  See [John Quirk's tutorial](https://rtutorialseries.blogspot.com.au/2009/11/r-tutorial-series-summary-and.html) on using basic descriptive statistics for more information.

```{r}
  # Compute basic descrpitive statistics for transcription score in pen_laptop1 data frame
  # Mean
    mean(pen_laptop1$transcription)
  # Median
    median(pen_laptop1$transcription) # Median
  # Standard Deviation
    sd(pen_laptop1$transcription)
  # 0 to 100th percentile in steps of 10%  
    quantile(pen_laptop1$transcription, probs = seq(0, 1, .1))
  # Example of summary function output 
    summary(pen_laptop1$transcription) 
```

### Summary Statistics By Group
You will sometimes want to compute descriptive statistics separately for multiple groups.  There are many ways to do this.  One option is to use the `group_by()` and `summarise()` functions in the `dplyr` package, for example:

```{r}
# Compute mean and standard deviation separately for the laptop and pen groups
  library(dplyr)
  pen_laptop1 %>%
    group_by(group) %>%
    summarise(
      mean = mean(transcription),
      sd = sd(transcription)
    )
```

For more information read the see the section on *Grouped Operations* in the [dplyr tutorial](https://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html).

Other options for computing descriptive statistics separately for different groups include using the inbuilt R function [aggregate()](http://www.inside-r.org/r-doc/stats/aggregate) or the [doBy package](https://cran.r-project.org/web/packages/doBy/vignettes/doBy.pdf).


## Data Visualisation (Plotting)

R has three systems that can be used for data visualisation - [Base graphics](http://rpubs.com/SusanEJohnston/7953), [lattice](https://rstudio-pubs-static.s3.amazonaws.com/12556_4e02f5564dc24b57b7a8f6d95d2a5cf7.html), and [ggplot2](http://ggplot2.org). The STHDA wesbite has [guides to creating graphics](http://www.sthda.com/english/wiki/data-visualization) using all three systems.

Base graphics , lattice, and ggplot2 all have functions for plotting histograms and dotpolots, covered in Chapter 3 of *Introduction to The New Statistics*.  Here are some examples of simple histograms produced by the three packages:

```{r}
# Examples of histograms created using the lattice graphics package
# Base histogram
  hist(pen_laptop1$transcription)
# lattice histogram
  library(lattice)
  histogram(~transcription, data = pen_laptop1)
# ggplot2  
  library(ggplot2)
  ggplot(pen_laptop1, aes(transcription) ) + geom_histogram(bins = 7, colour="black", fill="white")
```

If you are new to R and want to learn one graphics package, we recommend learning how to use `ggplot2` as it is the most powerful and flexible system.  Resources that will help you learn how to use `ggplot2` include:

* [Winston Chang's R Graphics Cookbook](http://www.cookbook-r.com/Graphs).
* [STHDA's ggplot2 essentials](http://www.sthda.com/english/wiki/ggplot2-essentials).
* Hadley Wickham's [ggplot2 book](https://www.amazon.com/ggplot2-Elegant-Graphics-Data-Analysis/dp/331924275X/ref=dp_ob_title_bk).
* [DataCamp's ggplot2 courses](https://www.datacamp.com/courses/data-visualization-with-ggplot2-1).
* [Harvard Introduction to ggplot2](http://tutorials.iq.harvard.edu/R/Rgraphics/Rgraphics.html).
* [R4Stats ggplot2 tutorial](http://r4stats.com/examples/graphics-ggplot2).
* [ggplot2 online documentation](http://docs.ggplot2.org/current/index.html).
* [R-Studio's Data Visualisation cheatsheet](https://www.rstudio.com/resources/cheatsheets).
* An [online workshop](http://moc.environmentalinformatics-marburg.de/gitbooks/publicationQualityGraphics/_book/index.html) about creating publication quality graphics using the ggplot2 and lattice graphics packages by Tim Appelhans.

If you are interested in learning the lattice package, a good place to start is the [STHDA Lattice Guide](http://www.sthda.com/english/wiki/lattice-graphs). R-Studio also have a good [Guide to R Graphics using lattice](https://rstudio-pubs-static.s3.amazonaws.com/12556_4e02f5564dc24b57b7a8f6d95d2a5cf7.html).  There is also a [book about the Lattice package](https://www.springer.com/gp/book/9780387759685).

### ggplot2 histogram and dotplot tutorials

* [R Bloggers - How to make a histogram with ggplot2](http://www.r-bloggers.com/how-to-make-a-histogram-with-ggplot2)
* [STHDA Histogram Tutorial](http://www.sthda.com/english/wiki/ggplot2-histogram-plot-quick-start-guide-r-software-and-data-visualization)
* [STHDA Guide to making dotplots](http://www.sthda.com/english/wiki/ggplot2-dot-plot-easy-function-for-making-a-dot-plot#dot-plot-with-multiple-groups)
* [ggplot2 documentation](http://docs.ggplot2.org/current/geom_dotplot.html) for the geom_dotplot() geom

## Z-Scores
[John Quick's tutorial](http://www.r-bloggers.com/r-tutorial-series-centering-variables-and-generating-z-scores-with-the-scale-function) shows how to use R's inbuilt scale() function to compute Z-scores.  See also [Seam Dolinar's
tutorial](http://stats.seandolinar.com/calculating-z-scores-with-r/) on calculating Z scores and finding tail probabilities.

## P-values and Confidence Intervals for a Single Sample
Kelly Black has written tutorials showing how to [compute p values using z- or t-distributions](http://www.cyclismo.org/tutorial/R/pValues.html), and how to [calculate confidence intervals for means using normal or t-distributions](http://www.cyclismo.org/tutorial/R/confidence.html).

## t.test() function
The `t.test()` function is built into R.  It produces confidence intervals and p-values for single samples, two independent groups, and paired samples.

```{r}
# Single Sample
t.test(pen_laptop1$transcription)

# Two Independent Groups - by default the Welch T-Test (equal variances not assumed) is calculated
t.test(transcription ~ group, data = pen_laptop1)

# Two Independent Groups - assuming variances are equal
t.test(transcription ~ group, data = pen_laptop1, var.equal = TRUE)

# Paired Samples
t.test(thomason1$pre, thomason1$post, paired = TRUE)
```

## MBESS package
Ken Kelly's [MBESS (Methods for the Behavioural and Social Sciences)](https://www3.nd.edu/~kkelley/site/MBESS.html) package contains numerous functions for computing confidence intervals for many effect sizes, including standardised mean differences, mean contrasts in one-way and factorial designs, unstandardised and standardised regression coefficients, R-squared, etc.  The MBESS also includes functions for power analysis and sample size planning for precision.  The [MBESS website](https://www3.nd.edu/~kkelley/site/MBESS.html) contains links to two journal articles about the package, and help files.

## effsize package
The `MBESS` package contains the functions `smd()` and `ci.smd` which can be used to compute the standardized mean difference for the two independent groups design, and a confidence interval.  However, using MBESS for this task is somewhat cumbersome as the effect size estimate and confidence interval have to be calculated in separate steps, and you also need to manually compute the sample size in each group in order to calculate the confidence interval.

```{r}
# Use dplyr package to extract transcription scores for 
# the laptop and pen groups in the pen_laptop1 dataset
   # library(dplyr) # load dplyr if it has not already been loaded
    laptop <- pen_laptop1 %>% filter(group == "Laptop")
    pen <- pen_laptop1 %>% filter(group == "Pen")
# Install MBESS if it is not already installed
    # install.packages("MBESS")
# Load MBESS library
    library(MBESS)
# Use the smd() function to compute d-biased (Cohen's d)
    es <- smd(laptop$transcription, pen$transcription)
# Sample sizes
    n1 <- nrow(pen)
    n2 <- nrow(laptop)
# Use ci.smd() to compute a 95% confidence interval for the biased estimate
    ci.smd(smd = es, n.1 = n1, n.2 = n2)
```

A faster way to compute the standardized mean difference and confidence interval is to use the `cohen.d` function in the [effsize](https://github.com/mtorchiano/effsize) package, which can be downloaded from CRAN.

```{r}
  # Install effsize package if it is not already installed
    install.packages("effsize")
  # Load library
    library(effsize)
  # Compute d-biased
    cohen.d(transcription ~ group, data = pen_laptop1, noncentral = TRUE)
  # Compute d-unbiased
    cohen.d(transcription ~ group, data = pen_laptop1, noncentral = TRUE, hedges.correction = TRUE)
```

The `cohen.d()` function can also be used to compute Cohen's d for paired designs, however note that the function uses the *standard deviation of the change scores* rather than the *standard deviation of the original scores* as the standardizer.

```{r}
  cohen.d(thomason1$pre, thomason1$post, noncentral = TRUE, paired = TRUE)

```

# Effect sizes for paired design, but no CIs
install.packages("PairedData")
library(PairedData)
p <- paired(thomason1$pre, thomason1$post)
effect.size(p)
?paired
PairedData::yuen.t.test(p)


# bootES
install.packages("bootES")
library(bootES)

# DescTools
# Single sample CI
library(DescTools)
MeanCI(thomason1$pre)
BinomCI() # CI for propoertion
BinomDiffCI() # CI for risk difference
BinomRatioCI() # CI for ratio of binomial proportions

laptop
pen

# Perfect t test - for avg as CI

#Effect sizes and 95% CI
#Cohen's d_av, using s_av as standardizer
https://github.com/Lakens/perfect-t-test/blob/master/Perfect_dependent_t-test.Rmd

require(MBESS) # to calculate non-central t limits

d_av <- m_diff/s_av
d_unb <- (1-(3/(4*(N-1)-1)))*d_av #note this is approximation of correction for Hedges'g - ESCI uses accurate correction, so should we.



x <- thomason1$pre
y <- thomason1$post
ci = 95






## Meta-Analysis
There are numerous R packages that can be used to conduct meta-analyses for a wide variety of effect sizes such as means, mean differences, standardized mean differences, proportions, odds rations, etc. See the [CRAN Meta-Analysis Task View](https://cran.r-project.org/web/views/MetaAnalysis.html) for a comprehensive list of them.

A popular and well documented package for conducting meta-analyses in R is [metafor](http://www.metafor-project.org).  See the detailed [metafor website](http://www.metafor-project.org) for more information.

[metagear](http://lajeunesse.myweb.usf.edu/publications.html) 
is a relatively new package which has meta-analytic capabilities as well as functions that help users conduct systematic reviews  and generate [PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses)](http://www.prisma-statement.org/) flow charts.  [This vignette](http://lajeunesse.myweb.usf.edu/metagear/metagear_basic_vignette.html) provides an overview of the metagrear package.

Other useful sources of information about conducting meta-analyses in R include:

* [A.C Del Re's Practical Tutorial](http://www.tqmp.org/RegularArticles/vol11-1/p037/p037.pdf) on conducting Meta-Analysis in R using the metafor and MAd packages
* Stephanie Kovalchik's [Tutorial on Meta-Analysis in R](http://www.edii.uclm.es/~useR-2013/Tutorials/kovalchik/kovalchik_meta_tutorial.pdf) from the 2013 useR! Conference
* Schwarzer, Carpenter, and Rucker's [Meta-Analysis with R](https://link.springer.com/book/10.1007/978-3-319-21416-0) book
* [R-Studio's tutorial](https://rstudio-pubs-static.s3.amazonaws.com/10913_5858762ec84b458d89b0f4a4e6dd5e81.html) on running meta-analyses in R using the metafor package
* Simon Knight's Guide to Meta-Analysis in R - [part 1](http://www.transplantevidence.com/blog/2014/07/meta-analysis-in-r-part-1-installing-the-software/) and [part 2](http://www.transplantevidence.com/blog/2014/08/meta-analysis-in-r-part-2-binary-data).
* Stephanie Hick's [Easy Introduction to Meta-Analysis in R](https://statisticalrecipes.blogspot.com.au/2014/01/easy-introduction-to-meta-analyses-in-r.html) using the meta package 


## multicon plots
For Cat's Eye Pictures, may also integrate into graphics section

egraph() - A function for plotting means as dots and error bars without caps around them
catseye() - A function for creating cat's eye plots of group means
diffPlot() - A function for creating difference plots for two group (both paired and independent) comparisons


## Correlation
Basic scatterplot
Adding a regression line

CIs on correlations
CI on difference between two independent correlations
Figure to display difference in two ind corr

## Regression
Calculation and figure for regression line in scatterplot

CI on the regression slope

lm() is the inbuilt R function for ordinary least-squares regression.
confint() gives confidence intervals on regression parameters

Also MBESS can do this (apaprently) as well as for standardized coefficients.

Link to graphics.

Show ggplot2 scatterplot with OLS line, maybe also show smoother, mention it can also fit robust and other regression lines.

Also countless other packages for fitting a variety of regression models in R.

Prediction intervals for individual values of Y at particular X values


## Categorical Data - Frequencies, Proportions, and Risk
CI for a proportion
CI for difference between two independent proprtions
Figure for CI on a single proportion
Figure for difference with CI

ESCI uses Newcombe 1998 methods

Ratio between two variables - frequency tables
CI on the difference
Chi Square / Phi Coefficients

vcd and vcdExtra packages for visualising categorical data

PropCIs
Does CIs for single, independent, and paired proportions.
Includes risk score CI.

library(pairwiseCI)	# for ARR NHS and RR using Score Method.  Uses Prop.diff and Prop.ratio	

And chi-square function I used for recent WCBCT analyses.

R manual to accompany Agresti's Categorical Data Analysis 2nd Ed by Laura Thompson
http://www.stat.ufl.edu/~aa/cda/Thompson_manual.pdf

## Extended Designs - One-Way and Factorial Designs

Independent Variable
One way independent groups design
CI for planned contrasts, on two means
Figures if possible

One way repeated esigns, if possible (beyond scope of book and ESCI)

ANOVA p values

## Extended Designs - Two Indepenent Variables
ESCi only does 2 x 2 design
Means adn CI on mean effects
CI on single DF interaction (as difference in differences)

Simple man effect

Nice to include two way repeated measures if possible

## Robust Methods
WRS and WRS2 packages

Trimmed means for two independent means

BootES 
https://web.williams.edu/Psychology/Faculty/Kirby/bootes-kirby-gerlanc-in-press.pdf




# Questions for Geoff and Bob

*Datasets I can't find referenced in text*

Name           |Section                  
---------------|-------------------------
flag_priming        |Ch 7 ???
super_golf          |Ch 7 ???
habituation         |Ch 8 ??? 
learning_genes      |Ch 8 ???
sensitization       |Ch 8 ???
ma_gambler_fallacy  |Ch9 ???
ma_anchor_adjust_chicago |Ch9 ???
ma_anchor_adjust_everest |Ch9 ???
ch11_ex7            |Ch 11 ???
ch12_ex3            |Ch 12 ???
inauthentic         |Ch 14 ???
iqboost             |Ch 14 ???
blame1              |Ch 15 ???
blame2              |Ch 15 ???
