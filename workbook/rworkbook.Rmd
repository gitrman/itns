---
title: "Introduction to the New Statistics - R Workbook"
author: "Authors here"
date: "16 May 2016"
output: 
  pdf_document: 
    latex_engine: lualatex
    number_sections: yes
    toc: yes
---
\newpage
# Overview / Getting Started
overview got go here.

Installing R and and either R-Studio or JGR/Deducer.

how to install and load the itns package

```{r}
 library(devtools)
 install_github("gitrman/itns")
```

How to load the library to make functions accessible.

```{r}
 library(itns)
```

Useful websites and tutorials.



[R-Studio Resources for Learning R](https://www.rstudio.com/resources/training/online-learning/#R)
(with links to interactive tutorials for beginners)

[R Bloggers - How to Learn R](http://www.r-bloggers.com/how-to-learn-r-2)

[Quick-R](http://www.statmethods.net)

[Cookbook for R](http://www.cookbook-r.com/)

[R Quick Reference Card](http://cran.r-project.org/doc/contrib/Short-refcard.pdf)


List a few particularly useful packages

dplyr

https://www3.nd.edu/~steve/computing_with_data/24_dplyr/dplyr.html

rehape and reshape2

etc

# Numerical Data Summaries

Materials relevant to ITNS Ch 3 here.

## Descriptive Statistics

List of inbuilt R functions to compute basic summary statistics.

Measure                     | R function
--------------------------- | --------
Mean                        | `mean()`
Median                      | `median()`
Minimum                     | `min()`
Maximum                     | `max()`
Range                       | `range()`
Interquartile Range         | `IQR()`
Variance                    | `var()`
Standard Deviation          | `sd()`
Percentiles                 | `quantile()`

## Examples

Using the pen laptop data.

Here are the first few cases:

```{r}
head(pen_laptop1)
```

Compute summary statistics:
```{r}
# Minimum
min(pen_laptop1$transcription)

# Maximum
max(pen_laptop1$transcription)

# Mean
mean(pen_laptop1$transcription)

# Median
median(pen_laptop1$transcription)

# 95th percentile
quantile(pen_laptop1$transcription, probs = .95)

# From the 5th to 95th percentiles, in steps of 5
quantile(pen_laptop1$transcription, probs = seq(from = .05, to = .95, by = .05))

# Variance
var(pen_laptop1$transcription)

# Standard deviation
sd(pen_laptop1$transcription)

# Range
range(pen_laptop1$transcription)

# Interquartile range
IQR(pen_laptop1$transcription)

```

## Summary function

```{r}
summary(pen_laptop1$transcription)
```


## Statitics by group

Using inbuilt `by()` function
```{r}
by(pen_laptop1$transcription, pen_laptop1$group, summary)
```

Using the more powerful and flexible `dplyr` package
```{r}
# Load the dplyr package
library(dplyr)
group_by(pen_laptop1, group) %>%
summarize(avg = mean(transcription))

# Going further - find the mean and standard deviation for each group
group_by(pen_laptop1, group) %>%
summarize(avg = mean(transcription),
          sd = sd(transcription)
          )
```

For a two-way design, blame1 dataset

There are two independent variables - *Socioeconomic status (ses)* (high or low) and  *race* (black or white).

```{r}
blame1 %>%
  group_by(race, ses) %>%
  summarize(avg = mean(blame), std.dev = sd(blame))
```


## Apply to multiple variables at a time

`summary()` function does this by default.

Example: college_survey1 data
```{r}
summary(college_survey1)
```

Using `dplyr` package.

Split by gender, then find mean for three variables (subjective well being, positive affect, negative affect)
```{r}
college_survey1 %>%
  group_by(gender) %>%
  summarise_each(funs(mean(., na.rm = TRUE)), subjective_well_being, positive_affect, negative_affect)
```

See also plyr, apply functions.

**useful Links**
[Quick R Guide to Basic Statistics in R](http://www.statmethods.net/stats/descriptives.html)


# Graphics
## Histograms
### Single Sample
```{r fig.height = 4, fig.width = 4}
library(lattice)
histogram(~transcription, data = pen_laptop1)
```

Alter the number of bins
```{r fig.height = 4, fig.width = 4}
histogram(~transcription, data = pen_laptop1, nint = 10)
```

Display count rather than count on the Y-axis
```{r fig.height = 4, fig.width = 4}
histogram(~transcription, data = pen_laptop1, nint = 10, type = "count")
```

### Multiple Samples
```{r fig.height = 4}
histogram(~transcription | group, data = pen_laptop1)
```


### Links
[Lattice Histogram Vignette](https://cran.r-project.org/web/packages/tigerstats/vignettes/histogram.html)


## Stacked Dot Plots

### Single group
A basic stacked dotplot generated using the `ggplot2` package.

```{r fig.height = 4, fig.width = 4}
library(ggplot2)
p <- ggplot(pen_laptop1, aes(x = transcription)) +
   geom_dotplot()
p
```

Change the bindwith, dotsize, and stack ratio
```{r fig.height = 4, fig.width = 4}
p <- ggplot(pen_laptop1, aes(x = transcription)) +
   geom_dotplot(binwidth = 1.5, dotsize = 1.2, stackratio = 1.5)
p
```

Center the dots
```{r fig.height = 4, fig.width = 4}
p <- ggplot(pen_laptop1, aes(x = transcription)) +
   geom_dotplot(binwidth = 1, dotsize = 1.2, stackratio = 1.5, stackdir = "center")
p
```

Rotate
```{r fig.height = 4, fig.width = 4}
p + coord_flip()
```


## Multiple groups
```{r fig.height = 4, fig.width = 4}
p <- ggplot(pen_laptop1, aes(x = group, y = transcription)) + 
      geom_dotplot(binaxis = "y", binwidth = 1, dotsize = 1.2, stackratio = 1.5, stackdir = "center")
p + coord_flip()
```

Add the mean of each group (as a red diamond)
```{r}
p + stat_summary(fun.y = mean, geom = "point", shape = 18,
                 size = 6, color = "red") +
  coord_flip()
```


## Clicable links to other sources of information
* [ggplot2 dotplot tuturial on the Statistical tools for high-throughput data analysis website](http://www.sthda.com/english/wiki/ggplot2-dot-plot-quick-start-guide-r-software-and-data-visualization).
* [Examples of how to generate dotplots using other R packages](http://eurekastatistics.com/r-s-flavours-of-stacked-dotplots).


## Other Links
* [Examples of Lattice Graphics](http://www.statmethods.net/advgraphs/trellis.html)


To add:
Add lattice book and vignettes

**ggplot2**
ggplot2 book
ggplot2 website
r bloggers ggplot2 cookbook


# Z-score and T-scores

## Compute z-scores

### `scale()`
The inbuilt `scale()` function converts raw scores to Z-scores. The sample mean is subtracted from each score, and the resulting values are divided by the sample standard deviation.
``` {r}
# For the pen_laptop dataset, convert all raw transcription scores to Z-scores
scale(pen_laptop1$transcription)
```

## Find a tail probability from a raw score
Use IQ example from Ch 4.
IQ tests have a population mean of 100 and SD of 15.
Therefore a person with a score of 115 would have a z score of 1, and score higher than about 84% of the population.

Use the inbuilt `pnorm()` function to find that probability.

``` {r}
# Expressed on a 0 - 1 scale
pnorm(q = 115, mean = 100, sd = 15)

# Expressed on 0 - 100 scale
pnorm(q = 115, mean = 100, sd = 15)* 100
```

## Find a tail probabilities from z-scores
``` {r}
# Z-score of 1
pnorm(q = 1)* 100

# Z-scores of -1.96 and 1.96
pnorm(q = c(-1.96, 1.96))* 100
```

There is no need to specify the mean and standard deviation as the defaults are 0 and 1.

## Find Z-scores given tail probabilities

``` {r}
# Find Z-scores corresponding to area under the curve 

qnorm(p = .025) # lower tail
qnorm(p = .025, lower.tail = FALSE) # upper tail
```

## Find raw scores given tail probabilities

``` {r}

# Find raw scores corresponding to area under the curve 

qnorm(p = .025, mean = 100, sd = 15) # lower tail
qnorm(p = .025, mean = 100, sd = 15, lower.tail = FALSE) # upper tail
```


## Find tail areas for chosen t

e.g., t-value of 2.145 and df = 14
``` {r}
pt(q = 2.145, df = 14) # upper tail
pt(q = -2.145, df = 14) # lower tail
pt(q = 2.145, df = 14, lower.tail = FALSE) # another to find lower tail probability
```

## Find critical t-values given df and tail area
``` {r}
qt(p = .025, df = 14) # lower tail critical value
qt(p = .025, df = 14, lower.tail = FALSE) # upper tail critical value
qt(p = .975, df = 14) # alternte way to find upper tail critical t value
```

## Calculate p-values given z-scores or t-scores
[Tutorial here](http://www.cyclismo.org/tutorial/R/pValues.html)


# Effect sizes and Confidence Intervals for Means and Mean Differences

## Confidence Interval for the Mean of a Single Sample
Using t-distribution.  There is no inbuilt function for Z as far as I know.

By default a 95% confidence interval for the mean is returned, as well as the estimated mean, t-value, degrees of freedom and p-valu.
``` {r}
t.test(pen_laptop1$transcription)
```

To use a different confidence level, use the `conf.level` argument.  For example, to compute a 99% confidence interval you would use

``` {r}
t.test(pen_laptop1$transcription, conf.level = .99)
```

## Two Independent Groups

### Mean Difference and Confidence Interval

#### Assuming unequal variances
This is the default in R.
``` {r}
t.test(transcription ~ group, data = pen_laptop1)
```

#### Assuming equal variances
``` {r}
t.test(transcription ~ group, data = pen_laptop1, var.equal = TRUE)
```

### Standaridzed Mean Difference

Use the `MBESS` package.

Load the package, and then extract the data to be used in the analysis.

``` {r}
library(dplyr)
library(MBESS)

# Extract transcription scores for the 'Laptop' group
x <- pen_laptop1 %>%  filter (group == "Laptop")

# Extract transcription scores for the 'Pen' group
y <- pen_laptop1 %>% filter (group == "Pen")

# Find the sample size for each group, excluding any missing data
nx <- na.omit(length(x$transcription))
ny <- na.omit(length(y$transcription))

## Find the standardized mean difference (biased)
d <- smd(x$transcription, y$transcription)
d

## Find unbiased standardized mean difference
du <- smd(x$transcription, y$transcription, Unbiased = TRUE)
du

# Compute a confidence interval
ci.smd (smd = d, n.1 = nx, n.2 = ny)
```

The `smd` and 'ci.smd` functions used the pooled standard deviation to compute **d**.

To use the standard deviation of one of the groups instead (e.g., when the homogeneity of variance assumption is not met), use the alternative functions `smd.c` and 'ci.smd.c`

For example, to use the laptop group standard deviation as the standardizer:

``` {r}

# Biased d, using the Laptop SD as the standardizer
d <- smd.c(Group.T = y$transcription, # Pen raw data
      Group.C = x$transcription # Laptop raw data
      )
d

# Confidence Interval
ci.smd.c (smd.c = d, n.C = nx, n.E = ny)
```


## Trimmed mean difference
Use WRS2 package.


## Two Dependent Groups

### Unstandardized Mean Change
Use thomason1 dataset.

``` {r}
t.test(thomason1$pre, thomason1$post, paired = TRUE)
```


### Standardized Mean Change

There is no MBESS function for this.

Need to write a function or show calculations.


## One and two-way designs

One-way independent groups

one way dependent groups

Two-way independent groups

Between by within

Contrasts


# Correlation

## Figures
scatterplot and other plots in R

corplot package

### Correlations and Confidence interval
``` {r}
cor(thomason1)
cor.test(thomason1$pre, thomason1$post)
```


### Difference in correlations
here. Have to look up.


# Regression

Using home_prices data.
``` {r}
mod <- lm(price ~ size, data = home_prices)
mod
summary(mod)
confint(mod)
anova(mod)
```

Use car package when type III sums of squares are needed.

``` {r}
library(car)
mod2 <- lm(price ~ size + location, data = home_prices)
anova(mod2) # default R method
Anova(mod2, type = "III") # type II SOS, same as SPSS
```

Diagnostic plots.

Confidence intervals for the Mean of Y, at every X.


# Frequencies, Proportions, Risks

PropCIs package does most of what we want

chisquare


# Precision and Planning

MBESS has functions for this.  Functions start with ss prefix.
eg ss.aipe.smd


# To do
## Cat's Eye Picture
## MOE for means ?